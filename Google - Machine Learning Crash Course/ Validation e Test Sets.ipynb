{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":" Validation e Test Sets.ipynb","private_outputs":true,"provenance":[{"file_id":"https://github.com/google/eng-edu/blob/main/ml/cc/exercises/validation_and_test_sets.ipynb","timestamp":1631183070746}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"4f3CKqFUqL2-"},"source":["# Validation Sets e Test Sets\n","\n","L'esercizio di Colab precedente ha valutato il modello allenato, usando i dati presenti nel training set, che non fornisce un forte segnale riguardo la qualità del modello. In questo colab, sperienterai con il validation set e il test set.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gV82DJO3kWpk"},"source":["## Il dataset\n","\n","Come nell'esercizio precedente, questo esercizio usa il [California Housing dataset](https://developers.google.com/machine-learning/crash-course/california-housing-data-description) per predire `median_house_value` per isolato. Come per molti dataset \"famosi\", il dataset California Housing consiste in realtà di due dataset separati, ognuno salvato in un .csv diverso:\n","\n","* Il training set situato nel file `california_housing_train.csv`.\n","* Il test set situato nel file `california_housing_test.csv`.\n","\n","Creiamo il validation set dividendo il training set che abbiamo scaricato in due parti:\n","\n","* un training set più piccolo\n","* e un validation set"]},{"cell_type":"markdown","metadata":{"id":"u84mXopntPFZ"},"source":["## Uso della versione aggiornata di TensorFlow\n"]},{"cell_type":"code","metadata":{"id":"FBhNIdUatOU6"},"source":["#@title EseguiTensorFlow 2.x\n","%tensorflow_version 2.x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S8gm6BpqRRuh"},"source":["## Import di moduli importanti\n"]},{"cell_type":"code","metadata":{"id":"9D8GgUovHbG0"},"source":["#@title Importa i moduli\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from matplotlib import pyplot as plt\n","\n","pd.options.display.max_rows = 10\n","pd.options.display.float_format = \"{:.1f}\".format"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xjvrrClQeAJu"},"source":["## Caricamento dei dataset da internet\n","\n","Il codice seguente carica i file .csv separati e crea i seguenti due DataFrames pandas:\n","* `train_df`, che contiene il training set.\n","* `test_df`, che contiene il test set.\n","\n"]},{"cell_type":"code","metadata":{"id":"zUnTc_wfd_o3"},"source":["train_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n","test_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P_KBdj2M_yjM"},"source":["## Scala i valori delle lables\n","\n","Il seguente codice scala `median_house_value`."]},{"cell_type":"code","metadata":{"id":"3hc7QQhaAFXD"},"source":["scale_factor = 1000.0\n","\n","# Scala la label del training set\n","train_df[\"median_house_value\"] /= scale_factor \n","\n","# Scala la label del test set\n","test_df[\"median_house_value\"] /= scale_factor"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FhessIIV8VPc"},"source":["## Caricamento delle funzioni per costruire ed allenare il modello \n","\n","Il seguente codice definisce due funzioni:\n","* `build_model`, che definisce la topografia del modello.\n","* `train_model`, che allena il modello, dando in output non solo il valore di loss per il training set ma anche il valore di loss per il validation set.\n"]},{"cell_type":"code","metadata":{"id":"bvonhK857msj"},"source":["#@title Define the functions that build and train a model\n","def build_model(my_learning_rate):\n","  \"\"\"Create and compile a simple linear regression model.\"\"\"\n","  # Most simple tf.keras models are sequential.\n","  model = tf.keras.models.Sequential()\n","\n","  # Add one linear layer to the model to yield a simple linear regressor.\n","  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))\n","\n","  # Compile the model topography into code that TensorFlow can efficiently\n","  # execute. Configure training to minimize the model's mean squared error. \n","  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n","                loss=\"mean_squared_error\",\n","                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n","\n","  return model               \n","\n","\n","def train_model(model, df, feature, label, my_epochs, \n","                my_batch_size=None, my_validation_split=0.1):\n","  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n","\n","  history = model.fit(x=df[feature],\n","                      y=df[label],\n","                      batch_size=my_batch_size,\n","                      epochs=my_epochs,\n","                      validation_split=my_validation_split)\n","\n","  # Gather the model's trained weight and bias.\n","  trained_weight = model.get_weights()[0]\n","  trained_bias = model.get_weights()[1]\n","\n","  # The list of epochs is stored separately from the \n","  # rest of history.\n","  epochs = history.epoch\n","  \n","  # Isolate the root mean squared error for each epoch.\n","  hist = pd.DataFrame(history.history)\n","  rmse = hist[\"root_mean_squared_error\"]\n","\n","  return epochs, rmse, history.history   \n","\n","print(\"Defined the build_model and train_model functions.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8gRu4Ri0D8tH"},"source":["## Definizione delle funzioni per disegnare i grafici\n","\n","La funzione `plot_the_loss_curve`disegna la loss vs. epoche sia per il training set sia per il validations set."]},{"cell_type":"code","metadata":{"id":"QA7hsqPZDvVM"},"source":["#@title Definizione della funzione di plot\n","\n","def plot_the_loss_curve(epochs, mae_training, mae_validation):\n","  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n","\n","  plt.figure()\n","  plt.xlabel(\"Epoch\")\n","  plt.ylabel(\"Root Mean Squared Error\")\n","\n","  plt.plot(epochs[1:], mae_training[1:], label=\"Training Loss\")\n","  plt.plot(epochs[1:], mae_validation[1:], label=\"Validation Loss\")\n","  plt.legend()\n","  \n","  # We're not going to plot the first epoch, since the loss on the first epoch\n","  # is often substantially greater than the loss for other epochs.\n","  merged_mae_lists = mae_training[1:] + mae_validation[1:]\n","  highest_loss = max(merged_mae_lists)\n","  lowest_loss = min(merged_mae_lists)\n","  delta = highest_loss - lowest_loss\n","  print(delta)\n","\n","  top_of_y_axis = highest_loss + (delta * 0.05)\n","  bottom_of_y_axis = lowest_loss - (delta * 0.05)\n","   \n","  plt.ylim([bottom_of_y_axis, top_of_y_axis])\n","  plt.show()  \n","\n","print(\"Defined the plot_the_loss_curve function.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jipBqEQXlsN8"},"source":["## Task 1: Sperimenta con lo splitting del validation set\n","\n","Nel seguente codice, vedrai una variabile chiamata `validation_split`, che abbiamo inizializzato a 0.2. La variabile `validation_split` specifica la proporzione del training set originale che servirà da validation set. Il training set originale contiene 17,000 dati. Di conseguenza, un `validation_split` di 0.2 significa che:\n","* 17,000 * 0.2 ~= 3,400 dati saranno nel validation set.\n","* 17,000 * 0.8 ~= 13,600 dati saranno nel training set.\n","\n","Il seguente codice costruisce un modello, lo allena sul training set, e valuta il modello costruito su entrambi i :\n","* validation set\n","* training set\n","Se i dati nel training set sono simili ai dati nel validation set, allora le due curve di loss e la loss finale dovrebbe essere quasi identica. Tuttavia, le curve di loss e il valore di loss finale **non** sono quasi identici. Hmmm,Questo è strano.\n","\n","Sperimenta con due o tre valori differenti per `validation_split`. Diversi valori di `validation_split` risolvono il problema?\n","\n"]},{"cell_type":"code","metadata":{"id":"knP23Taoa00a"},"source":["# Le seguenti variabili sono gli iperparametri.\n","learning_rate = 0.08\n","epochs = 30\n","batch_size = 100\n","\n","# Dividi il training set originale in un training set più piccolo e un validation set\n","validation_split = 0.6\n","\n","# Identifica la feature e la label\n","my_feature = \"median_income\"    # Il reddito medio in uno specifico isolato.\n","my_label = \"median_house_value\" # Il valore medio di una casa in uno specifico isolato.\n","\n","# Ovvero, stiamo andando a creare un modello che predice il valore di una casa\n","# basandosi soltanto sul reddito medio del quartiere\n","\n","# Ci sbarazziamo di qualsiasi versione pre-esistente del modello.\n","my_model = None\n","\n","# Invoca le funzioni di costruzione ed allenamento del modello.\n","my_model = build_model(learning_rate)\n","epochs, rmse, history = train_model(my_model, train_df, my_feature, \n","                                    my_label, epochs, batch_size, \n","                                    validation_split)\n","\n","plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"], \n","                    history[\"val_root_mean_squared_error\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TKa11JK4Pm3f"},"source":["## Task 2: Determina **perché** le curve di loss differiscono\n","\n","Non importa come dividi il training set e validation set, le curve di loss differiscono significativamente. Evidentemente, i dati nel training set non sono abbastanza simili ai dati nel validation set. Controintuitivo?Si, ma questo problema è abbastanza comune nel machine learning.\n","\n","Il tuo compito è determinare **perché** le curve di loss non sono molto simili. Come per molti problemi nel machine learning, il problema è radicato nei dati stessi. Per risolvere questo mistero del perché il training set e il validation set non sono quasi identici, scrivi una linea o due di [codice pandas](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb?utm_source=validation-colab&utm_medium=colab&utm_campaign=colab-external&utm_content=pandas_tf2-colab&hl=en) qui di seguito. Qui ci sono dei suggerimenti:\n","\n","* Il codice precedente splittava il training set originale in:\n","  * un training set più piccolo (il training set originale - validation set)\n","  * il validation set\n","* Di default, il metodo di pandas [`head`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html) da in output le *prime* 5 righe del Dataframe. Per vedere di più del training set, specifica la `n` come argomento di `head` ed assegna un numero positvo. "]},{"cell_type":"code","metadata":{"id":"VJQcAZkwJt_p"},"source":["# Write some code in this code cell.\n","train_df.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EnNvkFwwK8WY"},"source":["#@title Possibile risposta.\n","\n","# Esamina gli esempi da 0 a 4 e gli esempi da 25 a 29 del training set\n","train_df.head(n=1000)\n","\n","# Il training set originale è ordinato per longitudine.\n","# Apparentemente, la longitudine influenza la relazione tra\n","# total_rooms e il median_house_value.\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rw4xI1ZEckI8"},"source":["## Task 3. Risoluzione del problema\n","\n","Per risolvere il problema, mischia i dati nel training set prima di effettuare lo splitting in training set e validation set. Per fare questo, segui i seguenti step:\n","\n","1. Mischia i dati nel training set aggiungendo la seguente lina in qualsiasi punto prima della chiamata a `train_model`\n","\n","\n","```\n","  shuffled_train_df = train_df.reindex(np.random.permutation(train_df.index))\n","```                                    \n","\n","2. Passa `shuffled_train_df` (invece di `train_df`) come secondo argomento a `train_model` in modo che la chiamata diventi:\n","\n","```\n","  epochs, rmse, history = train_model(my_model, shuffled_train_df, my_feature, \n","                                      my_label, epochs, batch_size, \n","                                      validation_split)\n","```"]},{"cell_type":"code","metadata":{"id":"ncODhpv0h-LG"},"source":["#@title Double-click to view the complete implementation.\n","\n","# The following variables are the hyperparameters.\n","learning_rate = 0.08\n","epochs = 70\n","batch_size = 100\n","\n","# Split the original training set into a reduced training set and a\n","# validation set. \n","validation_split = 0.2\n","\n","# Identify the feature and the label.\n","my_feature = \"median_income\"    # the median income on a specific city block.\n","my_label = \"median_house_value\" # the median house value on a specific city block.\n","# That is, you're going to create a model that predicts house value based \n","# solely on the neighborhood's median income.  \n","\n","# Discard any pre-existing version of the model.\n","my_model = None\n","\n","# Shuffle the examples.\n","shuffled_train_df = train_df.reindex(np.random.permutation(train_df.index)) \n","\n","# Invoke the functions to build and train the model. Train on the shuffled\n","# training set.\n","my_model = build_model(learning_rate)\n","epochs, rmse, history = train_model(my_model, shuffled_train_df, my_feature, \n","                                    my_label, epochs, batch_size, \n","                                    validation_split)\n","\n","plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"], \n","                    history[\"val_root_mean_squared_error\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tKN239_miW8C"},"source":["Sperimenta con `validation_split` per rispondere alle seguenti domande:\n","\n","* Con il training set mischiato, la loss finale per il training set è più vicina alla loss finale del validation set?\n","* Con quale range di valori di `validation_split` il valore della loss finale per training set e validation set divergono vistosamente? Perché?"]},{"cell_type":"code","metadata":{"id":"-UAJ3Q86iz31"},"source":["#@title Risposte\n","\n","''' Si, dopo aver mischiato il training set originale, la loss finale per il training\n","set e il validation set sono diventate molto più simili.'''\n","\n","'''Se la validation_split <0.15 i valori della loss finale per il training\n","set e il validation set divergeranno significativamente. Apparentemente,\n","il validation set non contiene più dati a sufficienza.'''\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1PP-O8TOZOeo"},"source":["## Task 4: Use the Test Dataset to Evaluate Your Model's Performance\n","## Task 4: Usa il dataset di test per  valutare le performance del modello\n","\n","Il test set di solito funge come ultimo giudizio per la qualità del modello. Il test set può servire da giudice imparziale perché i suoi dati non sono stati usati in fase di allenamento del modello. Esegui il codice sottostante per valutare il modello con il test set:"]},{"cell_type":"code","metadata":{"id":"nd_Sw2cygOip"},"source":["x_test = test_df[my_feature]\n","y_test = test_df[my_label]\n","\n","results = my_model.evaluate(x_test, y_test, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qoyQKvsjmV_A"},"source":["Compara la radice dell'errore quadratico medio del modello quando valutato su ciascuno dei tre dataset:\n","* training set: cerca `root_mean_squared_error` nell'epoca finale di training.\n","* validaion set: cerca `val_root_mean_squared_error` nella epoca finale di training\n","* test set: esegui il codice precedente ed esamina `root_mean_squared_error`.\n","\n","Idealmente, la root mean squared error di tutte e tre dovrebbe essere simile. Lo sono?\n"]},{"cell_type":"code","metadata":{"id":"FxXtp-aVdIgJ"},"source":["#@title Risposta\n","\n","'''Nei nostri esperimenti, si, i valori di \n","rmse sono simili abbastanza. '''"],"execution_count":null,"outputs":[]}]}